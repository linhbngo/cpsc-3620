{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Introduction to Message Passing Interface (MPI)</center>\n",
    "### <center> Linh B. Ngo </center>\n",
    "### <center> CPSC 3620 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center>Message Passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Processes communicate via messages\n",
    "- Messages can be\n",
    "    - Raw data to be used in actual calculations\n",
    "    - Signals and acknowledgements for the receiving processes regarding the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center>History of MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Early 80s:**\n",
    "- Various message passing environments were developed\n",
    "- Many similar fundamental concepts\n",
    "- N-cube (Caltech), P4 (Argonne), PICL and PVM (Oakridge), LAM (Ohio SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1992: **\n",
    "- More than 80 reseachers from different institutions in US and Europe agreed to develop and implement a common standard for message passing\n",
    "- First meeting colocated with Supercomputing 1992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** After finalization: **\n",
    "- MPI becomes the *de-factor* standard for distributed memory parallel programming\n",
    "- Available on every popular operating system and architecture\n",
    "- Interconnect manufacturers commonly provide MPI implementations optimized for their hardware\n",
    "- MPI standard defines interfaces for C, C++, and Fortran\n",
    "    - Language bindings available for many popular languages (quality varies)\n",
    "    - MPI4PY: Bindings for python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1994: MPI-1 **\n",
    "- Communicators\n",
    "    - Information about the runtime environments\n",
    "    - Creation of customized topologies\n",
    "- Point-to-point communication\n",
    "    - Send and receive messages\n",
    "    - Blocking and non-blocking variations\n",
    "- Collectives\n",
    "    - Broadcast and reduce\n",
    "    - Gather and scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 1998: MPI-2 **\n",
    "- One-sided communication (non-blocking)\n",
    "    - Get & Put (remote memory access)\n",
    "- Dynamic process management\n",
    "    - Spawn\n",
    "- Parallel I/O\n",
    "    - Multiple readers and writers for a single file\n",
    "    - Requires file-system level support (LustreFS, PVFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** 2012: MPI-3 **\n",
    "- Revised remote-memory access semantic\n",
    "- Fault tolerance model\n",
    "- Non-blocking collective communication\n",
    "- Access to internal variables, states, and counters for performance evaluation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Set up MPI on Palmetto for C/C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Interactive mode:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`qsub -I -l select=1:ncpus=8:mpiprocs=8:mem=10gb,walltime=01:00:00`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`module load gcc/5.3.0 openmpi/1.10.3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*The module load command can be added to a script, which then is to be sourced from inside .bashrc to automate module loading. Calling the module load directly from inside .bashrc is not recommended.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Create a file named **hello.c** inside directory **cpsc3620** with the following content\n",
    "```\n",
    "#include <stdio.h>\n",
    "#include <sys/utsname.h>\n",
    "#include <mpi.h>\n",
    "int main(int argc, char *argv[]){\n",
    "    MPI_Init(&argc, &argv);\n",
    "    struct utsname uts;\n",
    "    uname (&uts);\n",
    "    printf(\"My process is on node %s.\\n\", uts.nodename);\n",
    "\tMPI_Finalize();\n",
    "\treturn 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Compile hello.c\n",
    "```\n",
    "mpicc hello.c -o hello\n",
    "```\n",
    "- Run hello.c\n",
    "```\n",
    "mpirun -np 2 ./hello\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Set up MPI on Palmetto for Python (Interactive via Jupyter Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Before launching JupyterHub**\n",
    "- Make sure that you have the command ``module load gcc/5.3.0 openmpi/1.10.3`` in your .jhubrc file. If you are using JupyterHub to edit the file, the server will need to be stopped and started again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Before launching a Jupyter notebook (only need to be done once)**\n",
    "- Install mpi4py by executing ``pip install --user mpi4py`` from a terminal. This needs to be done prior to launching a Jupyter notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Before launching a Jupyter notebook (any time you wish to run interactive MPI inside Jupyter Notebook)**\n",
    "- Inside a terminal (that must be kept open), execute the following command:\n",
    "```\n",
    "ipcluster start --n <Number of total possible cores> --profile=mpicluster\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In the first cell of your Jupyter notebook, type the followings:\n",
    "```\n",
    "import ipyparallel\n",
    "c = ipyparallel.Client(profile=\"mpicluster\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Test the attached cluster by running the following in a cell:\n",
    "```\n",
    "print(c.ids)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Any cell that contains MPI codes must be started with ``%%px``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel\n",
    "c=ipyparallel.Client(profile=\"mpicluster\")\n",
    "print(c.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] My process is on node node0263\n",
      "[stdout:1] My process is on node node0263\n",
      "[stdout:2] My process is on node node0263\n",
      "[stdout:3] My process is on node node0263\n",
      "[stdout:4] My process is on node node0263\n",
      "[stdout:5] My process is on node node0263\n",
      "[stdout:6] My process is on node node0263\n",
      "[stdout:7] My process is on node node0263\n",
      "[stdout:8] My process is on node node0263\n",
      "[stdout:9] My process is on node node0263\n",
      "[stdout:10] My process is on node node0263\n",
      "[stdout:11] My process is on node node0263\n",
      "[stdout:12] My process is on node node0263\n",
      "[stdout:13] My process is on node node0263\n",
      "[stdout:14] My process is on node node0263\n",
      "[stdout:15] My process is on node node0263\n",
      "[stdout:16] My process is on node node0342\n",
      "[stdout:17] My process is on node node0342\n",
      "[stdout:18] My process is on node node0342\n",
      "[stdout:19] My process is on node node0342\n",
      "[stdout:20] My process is on node node0342\n",
      "[stdout:21] My process is on node node0342\n",
      "[stdout:22] My process is on node node0342\n",
      "[stdout:23] My process is on node node0342\n",
      "[stdout:24] My process is on node node0342\n",
      "[stdout:25] My process is on node node0342\n",
      "[stdout:26] My process is on node node0342\n",
      "[stdout:27] My process is on node node0342\n",
      "[stdout:28] My process is on node node0342\n",
      "[stdout:29] My process is on node node0342\n",
      "[stdout:30] My process is on node node0342\n",
      "[stdout:31] My process is on node node0342\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "import socket\n",
    "print (\"My process is on node %s\" % (socket.gethostname()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> The working of MPI in a nutshell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- All processes are launched at the beginning of the program execution\n",
    "    - The number of processes are user-speficied\n",
    "    - Typically, this number is matched to the total number of cores available across the entire cluster\n",
    "- All processes have their own memory space and have access to the same source codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Basic parameters available to individual processes: **\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "name = MPI.Get_processor_name()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- MPI defines **communicator** groups for point-to-point and collective communications\n",
    "    - Unique IDs (**rank**) are defined for individual processes within a communicator group\n",
    "    - Communications are performed based on these IDs\n",
    "    - Default **global communication** (COMM_WORLD) contains all processes\n",
    "    - For $N$ processes, ranks go from $0$ to $N-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Hello world from process 10 running on host node0263 out of 32 processes\n",
      "[stdout:1] Hello world from process 2 running on host node0263 out of 32 processes\n",
      "[stdout:2] Hello world from process 0 running on host node0263 out of 32 processes\n",
      "[stdout:3] Hello world from process 4 running on host node0263 out of 32 processes\n",
      "[stdout:4] Hello world from process 6 running on host node0263 out of 32 processes\n",
      "[stdout:5] Hello world from process 8 running on host node0263 out of 32 processes\n",
      "[stdout:6] Hello world from process 12 running on host node0263 out of 32 processes\n",
      "[stdout:7] Hello world from process 14 running on host node0263 out of 32 processes\n",
      "[stdout:8] Hello world from process 11 running on host node0263 out of 32 processes\n",
      "[stdout:9] Hello world from process 1 running on host node0263 out of 32 processes\n",
      "[stdout:10] Hello world from process 5 running on host node0263 out of 32 processes\n",
      "[stdout:11] Hello world from process 9 running on host node0263 out of 32 processes\n",
      "[stdout:12] Hello world from process 7 running on host node0263 out of 32 processes\n",
      "[stdout:13] Hello world from process 15 running on host node0263 out of 32 processes\n",
      "[stdout:14] Hello world from process 13 running on host node0263 out of 32 processes\n",
      "[stdout:15] Hello world from process 3 running on host node0263 out of 32 processes\n",
      "[stdout:16] Hello world from process 20 running on host node0342 out of 32 processes\n",
      "[stdout:17] Hello world from process 26 running on host node0342 out of 32 processes\n",
      "[stdout:18] Hello world from process 30 running on host node0342 out of 32 processes\n",
      "[stdout:19] Hello world from process 16 running on host node0342 out of 32 processes\n",
      "[stdout:20] Hello world from process 27 running on host node0342 out of 32 processes\n",
      "[stdout:21] Hello world from process 22 running on host node0342 out of 32 processes\n",
      "[stdout:22] Hello world from process 21 running on host node0342 out of 32 processes\n",
      "[stdout:23] Hello world from process 17 running on host node0342 out of 32 processes\n",
      "[stdout:24] Hello world from process 28 running on host node0342 out of 32 processes\n",
      "[stdout:25] Hello world from process 25 running on host node0342 out of 32 processes\n",
      "[stdout:26] Hello world from process 18 running on host node0342 out of 32 processes\n",
      "[stdout:27] Hello world from process 19 running on host node0342 out of 32 processes\n",
      "[stdout:28] Hello world from process 23 running on host node0342 out of 32 processes\n",
      "[stdout:29] Hello world from process 29 running on host node0342 out of 32 processes\n",
      "[stdout:30] Hello world from process 24 running on host node0342 out of 32 processes\n",
      "[stdout:31] Hello world from process 31 running on host node0342 out of 32 processes\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "name = MPI.Get_processor_name()\n",
    "print (\"Hello world from process %s running on host %s out of %s processes\" % \n",
    "       (rank, name, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Ranks are used to enforce execution/exclusion of code segments within the original source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Process 0 is even\n",
      "[stdout:1] Process 2 is even\n",
      "[stdout:2] Process 1 is odd\n",
      "[stdout:3] Process 3 is odd\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "name = MPI.Get_processor_name()\n",
    "if (rank % 2 == 0):\n",
    "    print (\"Process %s is even\" % (rank))\n",
    "else:\n",
    "    print (\"Process %s is odd\" % (rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Ranks can be used as mean to calculate and distributed workload (data) among the processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:1] Process 2 has elements [10, 8, 7, 9]\n",
      "[stdout:2] Process 0 has elements [2, 13, 4, 3]\n",
      "[stdout:9] Process 1 has elements [5, 1, 0, 12]\n",
      "[stdout:15] Process 3 has elements [11, 6, 15, 14]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "import random\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "name = MPI.Get_processor_name()\n",
    "A = [2,13,4,3,5,1,0,12,10,8,7,9,11,6,15,14]\n",
    "#print (\"Elements %s and %s are assigned to process %s\" \n",
    "#       % (A[rank%15], A[1+rank%15], rank))\n",
    "if (rank < 4):\n",
    "    print (\"Process %s has elements %s\" % (rank, A[(4*rank):(4*rank+4)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Individual processes rely on communication (message passing) to enforce workflow\n",
    "    - Point-to-point Communication\n",
    "    - Collective Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Point-to-Point: Send and Receive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- Sender process:\n",
    "```\n",
    "comm.send(data, dest_rank)\n",
    "```\n",
    "- Receiver process:   \n",
    "```\n",
    "data = comm.recv(source_rank)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Send**\n",
    "```\n",
    "int MPI_Send(void *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint dest, \n",
    "\tint tag, \n",
    "\tMPI_Comm comm)\n",
    "```\n",
    "\n",
    "- MPI_Datatype may be MPI_BYTE, MPI_PACKED, MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG, MPI_FLOAT, MPI_DOUBLE, MPI_LONG_DOUBLE, MPI_UNSIGNED_CHAR\n",
    "- *dest* is the rank of the process the message is sent to\n",
    "- *tag* is an integer identify the message. Programmer is responsible for managing tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Recv**\n",
    "```\n",
    "int MPI_Recv(\n",
    "\tvoid *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint source, \n",
    "\tint tag, \n",
    "\tMPI_Comm comm,\n",
    "\tMPI_Status *status)\n",
    "```\n",
    "\n",
    "- MPI_Datatype may be MPI_BYTE, MPI_PACKED, MPI_CHAR, MPI_SHORT, MPI_INT, MPI_LONG, MPI_FLOAT, MPI_DOUBLE, MPI_LONG_DOUBLE, MPI_UNSIGNED_CHAR\n",
    "- *source* is the rank of the process from which the message was sent.\n",
    "- *tag* is an integer identify the message. MPI_Recv will only place data in the buffer if the tag from MPI_Send matches. The constant MPI_ANY_TAG may be used when the source tag is unknown or not important. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:2] 0.4942599923980231\n",
      "[stdout:9] 0.4942599923980231\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "import random\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "if (rank == 0):\n",
    "    send_pkg = random.random()\n",
    "    print (send_pkg)\n",
    "    comm.send(send_pkg, dest = 1, tag = 1)\n",
    "if (rank == 1):\n",
    "    recv_pkg = 0\n",
    "    recv_pkg = comm.recv(source = 0, tag = 1)\n",
    "    print (recv_pkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Blocking risks**\n",
    "- Send data larger than available network buffer (Blocking send)\n",
    "- Lost data (or missing sender) leading to receiver hanging indefinitely (Blocking receive)\n",
    "\n",
    "**Data types**\n",
    "- MPI4PY supports all default MPI's data types\n",
    "- MPI4PY uses *pickle* to facilitate sending and receiving of complex data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:9] {'class': 'cpsc3620', 'enrollments': 40, 'semester': 'Fall 2016'}\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "if rank == 0:\n",
    "    data = {'class': 'cpsc3620', 'semester': 'Fall 2016', \n",
    "            'enrollments': 40}\n",
    "    comm.send(data, dest=1, tag=11)\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0, tag=11)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:9] [1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "if rank == 0:\n",
    "    data = [1,2,3,4]\n",
    "    comm.send(data, dest=1, tag=11)\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0, tag=11)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> Collective Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Must involve ALL processes within the scope of a communicator\n",
    "- Unexpected behavior, including programming failure, if even one process does not participate\n",
    "- Types of collective communications:\n",
    "    - Synchronization: barrier\n",
    "    - Data movement: broadcast, scatter/gather\n",
    "    - Collective computation (aggregate data to perform computation): Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> <img src=\"pictures/mpi-collective.png\" width=\"700\"/> \n",
    "<sub> *https://computing.llnl.gov/tutorials/mpi/* </sub>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**broadcast:**\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- All processes:\n",
    "```\n",
    "<buffer at receiving process> = comm.bcast(<original data>, root=<root process>)\n",
    "```\n",
    "- *root* process is the one that has the original data initially. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```\n",
    "int MPI_Bcast(\n",
    "\tvoid *buf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```\n",
    "- Donâ€™t need to specify a TAG or DESTINATION\n",
    "- Must specify the SENDER (root)\n",
    "- Blocking call for all processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "0: 2\n",
      "0: 2\n",
      "[stdout:1] \n",
      "2: -1\n",
      "2: 2\n",
      "[stdout:2] \n",
      "1: -1\n",
      "1: 2\n",
      "[stdout:3] \n",
      "3: -1\n",
      "3: 2\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = 2\n",
    "else:\n",
    "    data = -1\n",
    "print (\"%s: %s\" % (rank, data))\n",
    "data = comm.bcast(data, root=0)\n",
    "print (\"%s: %s\" % (rank, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] {'key2': ('abc', 'xyz'), 'key1': [7, 2.72, (2+3j)]}\n",
      "[stdout:1] {'key1': [7, 2.72, (2+3j)], 'key2': ('abc', 'xyz')}\n",
      "[stdout:2] {'key1': [7, 2.72, (2+3j)], 'key2': ('abc', 'xyz')}\n",
      "[stdout:3] {'key2': ('abc', 'xyz'), 'key1': [7, 2.72, (2+3j)]}\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'key1' : [7, 2.72, 2+3j],\n",
    "            'key2' : ( 'abc', 'xyz')}\n",
    "else:\n",
    "    data = None\n",
    "data = comm.bcast(data, root=0)\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** How to save broadcast data into different variables on different processes? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "0: 2\n",
      "0: 2\n",
      "[stdout:1] \n",
      "2: -1\n",
      "2: 2\n",
      "[stdout:2] \n",
      "1: -1\n",
      "1: 2\n",
      "[stdout:3] \n",
      "3: -1\n",
      "3: 2\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = 2\n",
    "else:\n",
    "    data = -1\n",
    "print (\"%s: %s\" % (rank, data))\n",
    "data = comm.bcast(data, root=0)\n",
    "print (\"%s: %s\" % (rank, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**scatter:**\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- All processes:\n",
    "```\n",
    "<buffer at receiving process> = comm.scatter(<original array>, root=<root process>)\n",
    "```\n",
    "- *root* process is the one that has the original data array initially. \n",
    "- Data are divided according to rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Scatter**\n",
    "```\n",
    "int MPI_Scatter(\n",
    "\tvoid *sendbuf, \n",
    "\tint sendcount, \n",
    "\tMPI_Datatype sendtype, \n",
    "\tvoid *recvbuf,\n",
    "\tint recvcnt,\n",
    "\tMPI_Datatype recvtype,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 0: 1\n",
      "[stdout:1] 2: 9\n",
      "[stdout:2] 1: 4\n",
      "[stdout:3] 3: 16\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = [(i+1)**2 for i in range(size)]\n",
    "else:\n",
    "    data = None\n",
    "data = comm.scatter(data, root=0)\n",
    "print (\"%s: %s\" % (rank, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 0: {'key1': [7, 2.72, (2+3j)]}\n",
      "[stdout:1] 2: {'key3': ('abc', 'xyz')}\n",
      "[stdout:2] 1: {'key2': ('abc', 'xyz')}\n",
      "[stdout:3] 3: {'key4': ('cde', 'xyz')}\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = [{'key1' : [7, 2.72, 2+3j]},\n",
    "            {'key2' : ( 'abc', 'xyz')},\n",
    "            {'key3' : ( 'abc', 'xyz')},\n",
    "            {'key4' : ( 'cde', 'xyz')}]\n",
    "else:\n",
    "    data = None\n",
    "data = comm.scatter(data, root=0)\n",
    "print (\"%s: %s\" % (rank, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**gather:**\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- All processes:\n",
    "```\n",
    "<buffer at sending process> = comm.gather(<final array>, root=<root process>)\n",
    "```\n",
    "- *root* process is the one that receives the original data array initially. \n",
    "- Data arrive and are sorted at *root* according to rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Gather**\n",
    "```\n",
    "int MPI_Gather(\n",
    "\tvoid *sendbuff, \n",
    "\tint sendcount, \n",
    "\tMPI_Datatype sendtype, \n",
    "\tvoid *recvbuff,\n",
    "\tint recvcnt,\n",
    "\tMPI_Datatype recvtype,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "0: 1\n",
      "0: [1, 4, 9, 16]\n",
      "[stdout:1] \n",
      "2: 9\n",
      "2: None\n",
      "[stdout:2] \n",
      "1: 4\n",
      "1: None\n",
      "[stdout:3] \n",
      "3: 16\n",
      "3: None\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "data = (rank+1)**2\n",
    "print (\"%s: %s\" % (rank, data))\n",
    "data = comm.gather(data, root=0)\n",
    "if rank == 0:\n",
    "    print (\"%s: %s\" % (rank, data))\n",
    "else:\n",
    "    print (\"%s: %s\" % (rank, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** What happpens to variable *data* at the non-root process?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "0: 1\n",
      "0: [1, 4, 9, 16]\n",
      "[stdout:1] \n",
      "2: 9\n",
      "2: None\n",
      "[stdout:2] \n",
      "1: 4\n",
      "1: None\n",
      "[stdout:3] \n",
      "3: 16\n",
      "3: None\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "data = (rank+1)**2\n",
    "print (\"%s: %s\" % (rank, data))\n",
    "data = comm.gather(data, root=0)\n",
    "if rank == 0:\n",
    "    print (\"%s: %s\" % (rank, data))\n",
    "else:\n",
    "    print (\"%s: %s\" % (rank, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**reduce**\n",
    "```\n",
    "comm = MPI.COMM_WORLD\n",
    "```\n",
    "- All processes:\n",
    "```\n",
    "<final result at sending process> = comm.reduce(<data to be reduced>, op=MPI.<operation>, root=<root process>)\n",
    "```\n",
    "- *root* process is the one that receives the final reduced data initially. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Original MPI C Syntax: MPI_Reduce**\n",
    "```\n",
    "int MPI_Reduce(\n",
    "\tvoid *sendbuf, \n",
    "\tvoid *recvbuff,\n",
    "\tint count, \n",
    "\tMPI_Datatype datatype, \n",
    "\tMPI_OP op,\n",
    "\tint root, \n",
    "\tMPI_Comm comm);\n",
    "```\n",
    "- MPI_Op may be MPI_MIN, MPI_MAX, MPI_SUM, MPI_PROD (twelve total)\n",
    "- Programmer may add operations, must be commutative and associative\n",
    "- If count > 1, then operation is performed element-wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] The reduction is 6\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "sum = comm.reduce(rank, op=MPI.SUM, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print (\"The reduction is %s\" % (sum))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Anaconda 2.5.0 (Python 3)",
   "language": "python",
   "name": "anaconda_2.5.0_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
